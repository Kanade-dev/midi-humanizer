/**
 * Main Application Module
 * Coordinates all components for the MIDI Humanizer
 */

import { MIDIParser } from './modules/MIDIParser.js';
import { PhraseDetector } from './modules/PhraseDetector.js';
import { Humanizer } from './modules/Humanizer.js';
import { AudioPlayer } from './modules/AudioPlayer.js';
import { Visualizer } from './modules/Visualizer.js';
import { UI } from './modules/UI.js';

class MIDIHumanizerApp {
  constructor() {
    // Initialize modules
    this.midiParser = new MIDIParser();
    this.phraseDetector = new PhraseDetector();
    this.humanizer = new Humanizer();
    this.audioPlayer = new AudioPlayer();
    this.visualizer = new Visualizer();
    this.ui = new UI();
    
    // Application state
    this.originalMidiData = null;
    this.humanizedMidiData = null;
    this.currentAnalysis = null;
    this.lastUsedSettings = null;
    
    this.init();
  }

  /**
   * Initialize the application
   */
  init() {
    // Setup UI callbacks
    this.ui.setCallbacks({
      onFileUpload: (file) => this.handleFileUpload(file),
      onHumanize: (file, settings) => this.handleHumanize(file, settings),
      onPlayOriginal: (data) => this.handlePlayOriginal(data),
      onPlayHumanized: (data) => this.handlePlayHumanized(data),
      onStopPlayback: () => this.handleStopPlayback()
    });

    // Initialize UI
    this.ui.init();
    this.ui.initResponsive();

    // Setup audio player progress callback
    this.audioPlayer.setProgressCallback((progress) => {
      this.visualizer.updatePlaybackProgress(progress);
    });

    console.log('ğŸ¹ MIDI Humanizer initialized successfully');
  }

  /**
   * Handle file upload
   */
  async handleFileUpload(file) {
    try {
      const arrayBuffer = await file.arrayBuffer();
      this.originalMidiData = this.midiParser.parseMIDI(arrayBuffer);
      
      console.log('ğŸ“ File loaded:', {
        tracks: this.originalMidiData.tracks.length,
        ticksPerQuarter: this.originalMidiData.ticksPerQuarter
      });
      
      this.ui.showStatus('MIDIãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ', 'info');
    } catch (error) {
      console.error('File upload error:', error);
      this.ui.showError(`ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    }
  }

  /**
   * Handle humanization process
   */
  async handleHumanize(file, settings) {
    try {
      // Ensure file is loaded
      if (!this.originalMidiData) {
        await this.handleFileUpload(file);
      }

      if (!this.originalMidiData) {
        throw new Error('MIDIãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
      }

      this.lastUsedSettings = settings;
      
      // Analyze musical structure with enhanced phrase detection
      console.log('ğŸ§  Analyzing musical structure...');
      this.currentAnalysis = await this.analyzeMusicalStructure(
        this.originalMidiData, 
        settings
      );

      // Perform humanization
      console.log('ğŸ­ Applying humanization...');
      this.humanizedMidiData = this.humanizer.humanizeMIDI(
        this.originalMidiData,
        settings.style,
        settings.intensity,
        settings.seed,
        true // isUserUpload
      );

      // Initialize visualizer with results
      this.initializeVisualization();

      // Show results in UI
      this.ui.showResults(
        this.originalMidiData,
        this.humanizedMidiData,
        this.currentAnalysis
      );

      console.log('âœ… Humanization completed successfully');

    } catch (error) {
      console.error('Humanization error:', error);
      this.ui.showError(`å‡¦ç†ã‚¨ãƒ©ãƒ¼: ${error.message}`);
      throw error;
    }
  }

  /**
   * Analyze musical structure with enhanced phrase detection
   */
  async analyzeMusicalStructure(midiData, settings) {
    const analysis = {
      tracks: [],
      globalTempo: 120,
      timeSignature: [4, 4],
      phrases: [],
      enhancedFeatures: {}
    };

    // Analyze each track
    for (let i = 0; i < midiData.tracks.length; i++) {
      const track = midiData.tracks[i];
      
      // Enhanced phrase detection (2-1: ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œçŸ¥æ©Ÿèƒ½)
      const phrases = this.phraseDetector.identifyPhraseBoundaries(track, true);
      
      // Analyze chords for velocity variations (2-2: ã‚³ãƒ¼ãƒ‰ãªã©ã‚’æ¤œçŸ¥ã—è»½å¾®ãªãƒ™ãƒ­ã‚·ãƒ†ã‚£ã®æºã‚‰ãã‚’åŠ ãˆã‚‹)
      const chords = this.humanizer.analyzeChordProgression(track);
      
      // Detect dynamic peaks (2-3: ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒ”ãƒ¼ã‚¯ãªã©ã‚’æ¤œçŸ¥ã—ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’ä»˜ã‘ã‚‹)
      const dynamics = this.analyzeDynamicPeaks(track, phrases);
      
      // Other musical analysis
      const melody = this.humanizer.analyzeMelody(track);
      const rhythm = this.humanizer.analyzeRhythmicContext(track, settings.style);

      const trackAnalysis = {
        phrasing: phrases,
        chords: chords,
        melody: melody,
        rhythm: rhythm,
        dynamics: dynamics,
        enhancedFeatures: {
          phraseDetectionMode: settings.phraseDetectionMode,
          dynamicPeaks: dynamics.peaks || [],
          chordProgression: chords,
          velocityVariation: settings.velocityVariation,
          timingVariation: settings.timingVariation,
          dynamicRange: settings.dynamicRange
        }
      };

      analysis.tracks.push(trackAnalysis);
      
      // Store phrases for visualization
      analysis.phrases = analysis.phrases.concat(phrases);
    }

    // Enhanced analysis features
    analysis.enhancedFeatures = {
      totalPhrases: analysis.phrases.length,
      averagePhraseDuration: analysis.phrases.length > 0 ? 
        analysis.phrases.reduce((sum, p) => sum + (p.end - p.start), 0) / analysis.phrases.length / 1000 : 0,
      styleCharacteristics: this.getStyleCharacteristics(settings.style),
      processingSettings: settings
    };

    return analysis;
  }

  /**
   * Analyze dynamic peaks for phrase expression (2-3)
   */
  analyzeDynamicPeaks(track, phrases) {
    const notes = this.humanizer.extractNotesFromEvents(track);
    const peaks = [];
    
    phrases.forEach((phrase, phraseIndex) => {
      const phraseNotes = notes.filter(n => 
        n.startTime >= phrase.start && n.startTime <= phrase.end
      );
      
      if (phraseNotes.length > 0) {
        // Find velocity peaks within phrase
        const velocities = phraseNotes.map(n => n.velocity);
        const maxVelocity = Math.max(...velocities);
        const peakNote = phraseNotes.find(n => n.velocity === maxVelocity);
        
        if (peakNote) {
          const phrasePosition = (peakNote.startTime - phrase.start) / (phrase.end - phrase.start);
          
          peaks.push({
            phraseIndex: phraseIndex,
            time: peakNote.startTime,
            velocity: maxVelocity,
            position: phrasePosition,
            type: phrasePosition < 0.3 ? 'early' : phrasePosition > 0.7 ? 'late' : 'middle'
          });
        }
      }
    });

    return {
      peaks: peaks,
      averageVelocity: notes.length > 0 ? notes.reduce((sum, n) => sum + n.velocity, 0) / notes.length : 64,
      dynamicRange: notes.length > 0 ? Math.max(...notes.map(n => n.velocity)) - Math.min(...notes.map(n => n.velocity)) : 0
    };
  }

  /**
   * Get style characteristics for display (2-4)
   */
  getStyleCharacteristics(style) {
    const characteristics = {
      classical: {
        name: 'Classical',
        description: 'ã‚¯ãƒ©ã‚·ãƒƒã‚¯éŸ³æ¥½ã‚¹ã‚¿ã‚¤ãƒ«',
        effects: ['è¡¨ç¾åŠ›è±Šã‹ãªæ¼”å¥', 'å’Œå£°ã®éŸ¿ãã‚’é‡è¦–', 'ãƒ¬ã‚¬ãƒ¼ãƒˆå¥æ³•', 'ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®å¤‰åŒ–'],
        timing: { base: 15, variation: 1.2 },
        velocity: { base: 12, variation: 1.4 },
        characteristics: ['ãƒ•ãƒ¬ãƒ¼ã‚ºã®è‡ªç„¶ãªèµ·ä¼', 'å’ŒéŸ³ã®ç¾ã—ã„éŸ¿ã', 'æ­Œã†ã‚ˆã†ãªè¡¨ç¾']
      },
      pop: {
        name: 'Pop',
        description: 'ãƒãƒƒãƒ—ã‚¹ã‚¿ã‚¤ãƒ«',
        effects: ['ã‚°ãƒ«ãƒ¼ãƒ´æ„Ÿé‡è¦–', 'ã‚³ãƒ¼ãƒ‰æ„Ÿã®å¼·åŒ–', 'æ­Œã„ã‚„ã™ã„è¡¨ç¾', 'ãƒªã‚ºãƒ ã®å®‰å®šæ€§'],
        timing: { base: 8, variation: 0.8 },
        velocity: { base: 6, variation: 0.7 },
        characteristics: ['ãƒ“ãƒ¼ãƒˆã®å¼·èª¿', 'ãƒ¡ãƒ­ãƒ‡ã‚£ã®è¦ªã—ã¿ã‚„ã™ã•', 'ã‚³ãƒ¼ãƒ‰é€²è¡Œã®æ˜ç¢ºã•']
      },
      jazz: {
        name: 'Jazz',
        description: 'ã‚¸ãƒ£ã‚ºã‚¹ã‚¿ã‚¤ãƒ«',
        effects: ['ã‚¹ã‚¦ã‚£ãƒ³ã‚°æ„Ÿ', 'ã‚·ãƒ³ã‚³ãƒšãƒ¼ã‚·ãƒ§ãƒ³å¼·èª¿', 'ã‚¢ãƒ¼ãƒ†ã‚£ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'å³èˆˆçš„è¡¨ç¾'],
        timing: { base: 20, variation: 1.0 },
        velocity: { base: 15, variation: 1.1 },
        characteristics: ['ã‚¹ã‚¦ã‚£ãƒ³ã‚°ãƒªã‚ºãƒ ', 'ã‚³ãƒ¼ãƒ‰å¤‰åŒ–ã®å¼·èª¿', 'ã‚¢ãƒ‰ãƒªãƒ–çš„ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹']
      }
    };

    return characteristics[style] || characteristics.classical;
  }

  /**
   * Initialize visualization
   */
  initializeVisualization() {
    // Wait for DOM to be updated before initializing visualizer
    setTimeout(() => {
      if (!this.visualizer.init('visualizationContainer')) {
        console.warn('Visualizer initialization failed - container may not exist yet');
        return;
      }

      // Extract notes for visualization
      const originalNotes = this.extractNotesForVisualization(this.originalMidiData);
      const humanizedNotes = this.extractNotesForVisualization(this.humanizedMidiData);
      const phrases = this.currentAnalysis?.phrases || [];

      // Set visualization data
      this.visualizer.setData(originalNotes, humanizedNotes, phrases);

      console.log('ğŸ¨ Visualization initialized', {
        originalNotes: originalNotes.length,
        humanizedNotes: humanizedNotes.length,
        phrases: phrases.length
      });
    }, 100); // Small delay to ensure DOM is updated
  }

  /**
   * Extract notes for visualization
   */
  extractNotesForVisualization(midiData) {
    if (!midiData || !midiData.tracks) return [];
    
    const allNotes = [];
    
    midiData.tracks.forEach(track => {
      const notes = this.humanizer.extractNotesFromEvents(track);
      allNotes.push(...notes);
    });
    
    return allNotes.sort((a, b) => a.startTime - b.startTime);
  }

  /**
   * Handle play original
   */
  async handlePlayOriginal(data) {
    try {
      this.handleStopPlayback(); // Stop any current playback
      await this.audioPlayer.playOriginal(data || this.originalMidiData);
      this.visualizer.setPlaying(true);
      this.ui.updatePlaybackButtons('original');
    } catch (error) {
      console.error('Play original error:', error);
      this.ui.showError('ã‚ªãƒªã‚¸ãƒŠãƒ«å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    }
  }

  /**
   * Handle play humanized
   */
  async handlePlayHumanized(data) {
    try {
      this.handleStopPlayback(); // Stop any current playback
      await this.audioPlayer.playHumanized(data || this.humanizedMidiData);
      this.visualizer.setPlaying(true);
      this.ui.updatePlaybackButtons('humanized');
    } catch (error) {
      console.error('Play humanized error:', error);
      this.ui.showError('ãƒ’ãƒ¥ãƒ¼ãƒãƒŠã‚¤ã‚ºå¾Œå†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    }
  }

  /**
   * Handle stop playback
   */
  handleStopPlayback() {
    this.audioPlayer.stopPlayback();
    this.visualizer.setPlaying(false);
    this.ui.updatePlaybackButtons('stopped');
  }

  /**
   * Create download for humanized MIDI
   */
  createDownloadBlob() {
    if (!this.humanizedMidiData) {
      throw new Error('ãƒ’ãƒ¥ãƒ¼ãƒãƒŠã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“');
    }

    try {
      const midiArrayBuffer = this.midiParser.createMIDI(this.humanizedMidiData);
      return new Blob([midiArrayBuffer], { type: 'audio/midi' });
    } catch (error) {
      console.error('Download creation error:', error);
      throw new Error('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  }

  /**
   * Get application state for debugging
   */
  getState() {
    return {
      hasOriginalData: !!this.originalMidiData,
      hasHumanizedData: !!this.humanizedMidiData,
      hasAnalysis: !!this.currentAnalysis,
      isPlaying: this.audioPlayer.getPlaybackState().isPlaying,
      lastSettings: this.lastUsedSettings,
      moduleStatus: {
        midiParser: !!this.midiParser,
        phraseDetector: !!this.phraseDetector,
        humanizer: !!this.humanizer,
        audioPlayer: !!this.audioPlayer,
        visualizer: !!this.visualizer,
        ui: !!this.ui
      }
    };
  }

  /**
   * Cleanup resources
   */
  cleanup() {
    this.handleStopPlayback();
    this.audioPlayer.cleanup();
  }
}

// Initialize the application when DOM is loaded
document.addEventListener('DOMContentLoaded', () => {
  window.midiHumanizerApp = new MIDIHumanizerApp();
});

// Cleanup on page unload
window.addEventListener('beforeunload', () => {
  if (window.midiHumanizerApp) {
    window.midiHumanizerApp.cleanup();
  }
});

export default MIDIHumanizerApp;